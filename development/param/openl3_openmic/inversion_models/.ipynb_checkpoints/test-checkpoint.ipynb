{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloaders.audio_dataset as dataset\n",
    "import models.inversion_v2 as inversion_model\n",
    "from abstract_model import AbstractModel\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchaudio.functional as F\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from pytorch_lightning.core.saving import load_hparams_from_yaml\n",
    "\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dft = 2048\n",
    "n_mels = 128\n",
    "n_hop = 242\n",
    "asr = 48000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_run(path):\n",
    "    event_acc = event_accumulator.EventAccumulator(path)\n",
    "    event_acc.Reload()\n",
    "    data = {}\n",
    "\n",
    "    for tag in sorted(event_acc.Tags()[\"scalars\"]):\n",
    "        x, y = [], []\n",
    "\n",
    "        for scalar_event in event_acc.Scalars(tag):\n",
    "            x.append(scalar_event.step)\n",
    "            y.append(scalar_event.value)\n",
    "\n",
    "        data[tag] = (np.asarray(x), np.asarray(y))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-331400c487bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'checkpoints'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mepoch_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{epoch_file}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# TEST - SPECIFIC VERSION - MSE loss and amplitude prediction\n",
    "\n",
    "algo = \"inversion_v2\"\n",
    "data_path = \"/scratch/prs392/incubator/data/OpenMic/\"\n",
    "checkpoint_path = f\"/scratch/prs392/incubator/checkpoints/openl3_openmic/{algo}/\"\n",
    "# experiment_name = \"train_1000_audio_with_specific_hparams_with_emb_means_and_stds\"\n",
    "experiment_name = \"train_with_specific_hparams\"\n",
    "\n",
    "AudioDatasetWithAmp = dataset.AudioDataset\n",
    "InversionV2 = inversion_model.InversionV2\n",
    "\n",
    "data_paths = {}\n",
    "data_paths['train'] = os.path.join(data_path, 'train-clean-360')\n",
    "data_paths['val'] = os.path.join(data_path, 'dev-clean')\n",
    "data_paths['test'] = os.path.join(data_path, 'test-clean')\n",
    "\n",
    "d = os.path.join(checkpoint_path, experiment_name)\n",
    "versions = [o for o in os.listdir(d) if os.path.isdir(os.path.join(d,o))]\n",
    "\n",
    "versions = sorted(versions)\n",
    "\n",
    "for version in versions:\n",
    "    if version == 'version_0':\n",
    "        hparam_path = os.path.join(checkpoint_path, experiment_name, version, 'hparams.yaml')\n",
    "#         hparams_new = load_hparams_from_yaml(hparam_path)\n",
    "\n",
    "\n",
    "hparams_new = {\n",
    "    'batch_size': 64,\n",
    "    'lr': 0.0004136762567284789,\n",
    "    'lr_type': 'adam',\n",
    "    'scheduler_epoch': 1,\n",
    "    'scheduler_step_size': 0.9465236907824874\n",
    "}\n",
    "\n",
    "version = 'version_0'\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_path, experiment_name, version, 'checkpoints')\n",
    "epoch_file = [o for o in os.listdir(checkpoint_path) if os.path.isfile(os.path.join(checkpoint_path,o))][1]\n",
    "\n",
    "PATH = os.path.join(checkpoint_path, f'{epoch_file}') \n",
    "\n",
    "print(hparams_new)\n",
    "print(epoch_file)\n",
    "\n",
    "model = AbstractModel.load_from_checkpoint(PATH, hparams=hparams_new, \n",
    "                                            data_paths = data_paths, \n",
    "                                            dataset_model = AudioDatasetWithAmp,\n",
    "                                            model = InversionV2(), \n",
    "                                            criterion = nn.MSELoss())\n",
    "\n",
    "model = model.eval()\n",
    "\n",
    "train_dataset = AudioDatasetWithAmp(\n",
    "    root_dir=data_paths['test'], \n",
    "    num_audios = 1000, \n",
    "    return_amp = True\n",
    ")\n",
    "# train_dataset = AudioDatasetWithAmp(root_dir=data_paths['test'], num_audios = 1000, return_amp = True)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=hparams_new['batch_size'], shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
